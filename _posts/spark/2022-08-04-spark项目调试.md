---
layout: post
title:  "spark 项目调试"
date:   2022-08-04 14:25:10 +0800
categories: note
tags: spark scala
---


### 基础的项目配置
+ 配置git
+ 从github 上下载项目,等待maven 下载依赖项
+ 下载idea 的scala 插件
+ 下载scala,java sdk 
  以上步骤主要遇到的困难时github和idea 下载项目奇慢的问题（可以通过挂梯子，配国内镜像等解决）

### build
+ 按照官方文档的build 步骤指引,由于指引的工具都是shell 脚本,所以启动 windows 下linux 子系统进行执行（wsl）
  第一次build 下载依赖 什么的超级久，下载了一下午才搞定。
  ![成功标志](/assets/pic/spark_build.jpg)

  build 完成后生成的jar 包都在 `$项目路径\assembly\target\scala-2.12\jar` 里面

```
  proj_dirctory $  wsl // 启动wsl
  proj_dirctory $  ./build/mvn -DskipTests clean package
  # 第一个错 /usr/bin/env: ‘bash\r’: No such file or directory   由于文件分隔符的问题
  #在idea 设置中修改 windows 分割符（File-> setting ->code style;File->File properties）
  ./build/mvn -pl :spark-streaming_2.12 clean install
  ./build/mvn -pl :spark-core_2.12 clean install
```

一些优化操作
查阅博客来尝试优化  我的build操作

[how-to-speed-up-your-maven-build](https://www.jrebel.com/blog/how-to-speed-up-your-maven-build)

```
//  mvn -T 8 install   使用8线程来并行build 项目 50min->10min
// mvn -T 1C install -- will use 1 thread per available CPU core
 ./build/mvn -T 8 -pl :spark-core_2.12 clean install // build 指定包
 ./build/mvn -T 1C install -pl $moduleName -am —offline  // 拒绝自动下载权限
 ./build/mvn -T 1C install -pl :spark-core_2.12 -am —offline
```

###  配置spark-version-info.properties
      刚开始直接启动 spark-shell 报找不到spark-version-info.properties，后来经过查询后发现需要先生成版本信息，然后在spark-core的 resource 中添加才可以

```
// 使用项目自带生产version-info 的脚本生成   version info
build/spark-build-info  ${spark-version-info.properties 生成的路径}
cd 项目路径\assembly\target\scala-2.12\jar
mkdir spark-core_2.12-3.4.0-SNAPSHOT
cd spark-core_2.12-3.4.0-SNAPSHOT
jar -xf spark-core_2.12-3.4.0-SNAPSHOT.jar 解压已经build 好的jar
// 移动生成的  spark-version-info.properties 到这个目录
jar -cf0M spark-core_2.12-3.4.0-SNAPSHOT.jar * 打包这个 目录
```
### 启动shell
```
cd bin 
spark-shell

// spark shell 正常启动
Welcome to
____              __
/ __/__  ___ _____/ /__
_\ \/ _ \/ _ `/ __/  '_/
/___/ .__/\_,_/_/ /_/\_\   version 3.4.0-SNAPSHOT
/_/

```

### 一些其它操作

```
# 使用maven 跑测试
build/mvn -Dtest=none -DwildcardSuites=org.apache.spark.scheduler.DAGSchedulerSuite test
```